{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright **`(c)`** 2024 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free under certain conditions â€” see the [`license`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel died. Error: /home/andre/.conda/envs/rl-venv/bin/python: No module named ipykernel_launcher... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from icecream import ic\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_f(x: np.ndarray) -> np.ndarray:\n",
    "    return x[0] + np.sin(x[1]) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 10_000\n",
    "TRAIN_SIZE = 1000\n",
    "\n",
    "x_validation = np.vstack(\n",
    "    [\n",
    "        np.random.random_sample(size=TEST_SIZE) * 2 * np.pi - np.pi,\n",
    "        np.random.random_sample(size=TEST_SIZE) * 2 - 1,\n",
    "    ]\n",
    ")\n",
    "y_validation = true_f(x_validation)\n",
    "train_indexes = np.random.choice(TEST_SIZE, size=TRAIN_SIZE, replace=False)\n",
    "x_train = x_validation[:, train_indexes]\n",
    "y_train = y_validation[train_indexes]\n",
    "assert np.all(y_train == true_f(x_train)), \"D'ho\"\n",
    "\n",
    "np.savez('problem_0.npz', x=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d3584"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = np.load('problem_0.npz')\n",
    "x = problem['x']\n",
    "y = problem['y']\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE (train): {100*np.square(y_train-d3584.f(x_train)).sum()/len(y_train):g}\")\n",
    "print(f\"MSE (real) : {100*np.square(y_validation-d3584.f(x_validation)).sum()/len(y_validation):g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH = 10\n",
    "STATES = tuple(range(LENGTH))\n",
    "\n",
    "ACTIONS = {s: {-1, +1} for s in range(1, LENGTH-1)}\n",
    "ACTIONS[0] = {}\n",
    "ACTIONS[LENGTH-1] = {}\n",
    "REWARD = {(s,a) for s in STATES for a in ACTIONS[s]}\n",
    "REWARD[(1, -1)] = 10\n",
    "REWARD[(LENGTH-2, 1)] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random policy\n",
    "def random_policy(s):\n",
    "    available_actions = ACTIONS[s]\n",
    "    return {(1 / len(available_actions), a) for a in ACTIONS[s]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Greedy polocy\n",
    "def greedy_policy(s):\n",
    "    policy = dict()\n",
    "    for s in STATES:\n",
    "        if s==0 or s==LENGTH - 1: # Don't move if in best state\n",
    "            policy[s] = {}\n",
    "        elif REWARD(s,-1) + value[s-1] > REWARD(s,+1) + value[s+1]: # Going left is more useful\n",
    "            policy[s] = (-1, 1)\n",
    "        elif REWARD(s,-1) + value[s-1] > REWARD(s, +1) + value[s+1]: # Going right is more useful\n",
    "            policy[s] = (1, 1)\n",
    "        else:\n",
    "            policy[s] = (0.5, -1), (0.5, +1)\n",
    "    \n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel died. Error: /home/andre/.conda/envs/rl-venv/bin/python: No module named ipykernel_launcher... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Test random policy\n",
    "value = {s: 0 for s in STATES}\n",
    "new_value = dict()\n",
    "TRAIN_STEPS = 100\n",
    "\n",
    "for _ in tqdm(range(TRAIN_STEPS)):\n",
    "    for s in STATES:\n",
    "        for (p,a) in random_policy(s):\n",
    "            new_value[s] += p * (REWARD[s, a] + value[s+a])\n",
    "    value = dict(new_value)\n",
    "    \n",
    "print(value) # This should be the optimal value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test greedy policy\n",
    "value = {s: 0 for s in STATES}\n",
    "TRAIN_STEPS = 100\n",
    "\n",
    "for _ in tqdm(range(TRAIN_STEPS)):\n",
    "    policy = greedy_policy(value)\n",
    "    \n",
    "    for s in STATES:\n",
    "        value[s] = 0\n",
    "        for (p, a) in policy(s):\n",
    "            value[s] += p * (REWARD[s, a] + value[s + a])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
